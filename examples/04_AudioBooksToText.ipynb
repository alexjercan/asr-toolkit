{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04_AudioBooksToText.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "adf8e0fca127476b85ed35bea1a333ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b603eae242394b3caa6a3f6a8a657652",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36fc9f21bda14cb1986fe0705169f84c",
              "IPY_MODEL_000a22e6f7bd4f5f933dae2cfef8bf50",
              "IPY_MODEL_2824aafc663b4f5ca0973aed2c02e90f"
            ]
          }
        },
        "b603eae242394b3caa6a3f6a8a657652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36fc9f21bda14cb1986fe0705169f84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0087ac6076d48bb9649e865383b5004",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4771ee17479546e890742f7787fc45cc"
          }
        },
        "000a22e6f7bd4f5f933dae2cfef8bf50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f11e049b894547ef8547dfea003b06a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 346663984,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 346663984,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e934e433af424c0b86ac6421a2f1e910"
          }
        },
        "2824aafc663b4f5ca0973aed2c02e90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5dac326a7db4da9a03a4c183c6388ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331M/331M [00:17&lt;00:00, 20.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eed3127800854392afc1f6b3d245fe36"
          }
        },
        "d0087ac6076d48bb9649e865383b5004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4771ee17479546e890742f7787fc45cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f11e049b894547ef8547dfea003b06a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e934e433af424c0b86ac6421a2f1e910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5dac326a7db4da9a03a4c183c6388ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eed3127800854392afc1f6b3d245fe36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSiqSDo0oIL1"
      },
      "source": [
        "\"\"\"\n",
        "You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
        "\n",
        "Instructions for setting up Colab are as follows:\n",
        "1. Open a new Python 3 notebook.\n",
        "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
        "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
        "4. Run this cell to set up dependencies.\n",
        "5. Restart the runtime (Runtime -> Restart Runtime) for any upgraded packages to take effect\n",
        "\"\"\"\n",
        "# If you're using Google Colab and not running locally, run this cell.\n",
        "\n",
        "## Install dependencies\n",
        "!pip install wget\n",
        "!apt-get install sox libsndfile1 ffmpeg\n",
        "!pip install unidecode\n",
        "!pip install matplotlib>=3.3.2\n",
        "!apt-get install libsox-fmt-all libsox-dev sox > /dev/null\n",
        "!pip install torchaudio\n",
        "!python -m pip install git+https://github.com/facebookresearch/WavAugment.git > /dev/null\n",
        "!pip install wandb\n",
        "\n",
        "## Install NeMo\n",
        "BRANCH = 'main'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n",
        "\n",
        "# install beam search decoder\n",
        "!apt-get install -y swig\n",
        "!git clone https://github.com/NVIDIA/NeMo -b \"$BRANCH\"\n",
        "!cd NeMo && bash scripts/asr_language_modeling/ngram_lm/install_beamsearch_decoders.sh\n",
        "\n",
        "%rm -rf asr\n",
        "!git clone https://github.com/alexjercan/asr-toolkit.git asr > /dev/null\n",
        "\n",
        "\"\"\"\n",
        "Remember to restart the runtime for the kernel to pick up any upgraded packages (e.g. matplotlib)!\n",
        "Alternatively, you can uncomment the exit() below to crash and restart the kernel, in the case\n",
        "that you want to use the \"Run All Cells\" (or similar) option.\n",
        "\"\"\"\n",
        "# exit()\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch1MxTVao8KZ",
        "outputId": "11f0a6ce-3856-4a08-e01c-53241b4dba8f"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import wget\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "import nemo\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import augment\n",
        "import torchaudio\n",
        "import torchaudio.datasets\n",
        "from torchaudio.datasets.librispeech import load_librispeech_item\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "from datetime import datetime as dt\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from asr.metrics import ASRMetricFunction, CTCLossFunction\n",
        "from asr.visualisation import play_audio, print_err_html, print_stats, plot_waveform\n",
        "from asr.general import set_parameter_requires_grad, load_checkpoint, save_checkpoint, tensors_to_device, tensor_to_string\n",
        "from asr.models import BeamSearchDecoderWithLM\n",
        "from asr.datasets import LibriSpeechBookDataset\n",
        "from IPython.display import YouTubeVideo, clear_output\n",
        "clear_output()\n",
        "\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NAME='stt_en_jasper10x5dr'\n",
        "LM_3GRAM_PATH = '3-gram.arpa'\n",
        "ROOT = os.path.join(\".\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setup complete. Using torch 1.9.0+cu102 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEc5H3bFpLAy"
      },
      "source": [
        "def download_lm(lm_path):\n",
        "    %rm -v \"{lm_path}\"*\n",
        "    !wget \"https://www.openslr.org/resources/11/{lm_path}.gz\" -O \"{lm_path}.gz\"\n",
        "    !gzip -cdv \"{lm_path}.gz\" > \"{lm_path}\"\n",
        "\n",
        "model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=MODEL_NAME, strict=False).to(DEVICE)\n",
        "\n",
        "VOCABULARY = list(map(lambda x: x.upper(), model.decoder.vocabulary))\n",
        "vocab = VOCABULARY + ['<pad>']\n",
        "BLANK = len(vocab) - 1 \n",
        "\n",
        "DICTIONARY = dict(zip(vocab, range(len(vocab))))\n",
        "LABELS = {v:k for k, v in DICTIONARY.items()}\n",
        "\n",
        "if not os.path.exists(LM_3GRAM_PATH):\n",
        "    download_lm(LM_3GRAM_PATH)\n",
        "beam_search_lm = BeamSearchDecoderWithLM(\n",
        "    vocab=VOCABULARY,\n",
        "    beam_width=16,\n",
        "    alpha=1.5, beta=1.5,\n",
        "    lm_path=LM_3GRAM_PATH,\n",
        "    num_cpus=max(os.cpu_count(), 1))\n",
        "clear_output()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "adf8e0fca127476b85ed35bea1a333ca",
            "b603eae242394b3caa6a3f6a8a657652",
            "36fc9f21bda14cb1986fe0705169f84c",
            "000a22e6f7bd4f5f933dae2cfef8bf50",
            "2824aafc663b4f5ca0973aed2c02e90f",
            "d0087ac6076d48bb9649e865383b5004",
            "4771ee17479546e890742f7787fc45cc",
            "f11e049b894547ef8547dfea003b06a7",
            "e934e433af424c0b86ac6421a2f1e910",
            "f5dac326a7db4da9a03a4c183c6388ee",
            "eed3127800854392afc1f6b3d245fe36"
          ]
        },
        "id": "BDLtCr2JztJZ",
        "outputId": "90b42dc5-ab33-488c-eb79-b97087926ed3"
      },
      "source": [
        "dev_dataset = LibriSpeechBookDataset(root=ROOT, url=\"dev-clean\", folder_in_archive=\"LibriSpeech\", download=True)\n",
        "test_dataset = LibriSpeechBookDataset(root=ROOT, url=\"test-clean\", folder_in_archive=\"LibriSpeech\", download=True)\n",
        "train_dataset = LibriSpeechBookDataset(root=ROOT, url=\"train-clean-100\", folder_in_archive=\"LibriSpeech\", download=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adf8e0fca127476b85ed35bea1a333ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Zv8lQ1huTV"
      },
      "source": [
        "def get_best_transcriptions(transcriptions):\n",
        "    return list(map(lambda xs: xs[0][1], transcriptions))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "Ws9lxkwhkjug",
        "outputId": "bf0e5576-e39d-4dda-e4ae-8cc57977b97e"
      },
      "source": [
        "loop = tqdm(train_dataset, position=0, leave=True)\n",
        "df = pd.DataFrame(None, columns=[\"REAL TEXT\", \"BOOK TITLE\", \"DURATION\"])\n",
        "\n",
        "for batch_idx, (waveform, transcription, booktitle, duration) in enumerate(loop):\n",
        "    df = df.append({\"REAL TEXT\": transcription, \"BOOK TITLE\": booktitle, \"DURATION\": duration}, ignore_index=True)\n",
        "\n",
        "loop.close()\n",
        "df.to_csv(\"train-clean-100.csv\")\n",
        "files.download(\"train-clean-100.csv\")\n",
        "\n",
        "print(df[\"REAL TEXT\"].apply(lambda t: len(t.split(\" \"))).describe())\n",
        "print(df[\"DURATION\"].describe())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [03:09<00:00,  1.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_42c8f880-c14c-4bf5-8c32-e0dfb250c759\", \"train-clean-100.csv\", 5279692)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "count      305.000000\n",
            "mean      3226.773770\n",
            "std       2456.083601\n",
            "min         78.000000\n",
            "25%       1445.000000\n",
            "50%       2792.000000\n",
            "75%       4135.000000\n",
            "max      19479.000000\n",
            "Name: REAL TEXT, dtype: float64\n",
            "count    305.000000\n",
            "mean      19.675639\n",
            "std       15.336142\n",
            "min        0.540000\n",
            "25%        9.170000\n",
            "50%       17.020000\n",
            "75%       25.110000\n",
            "max      127.620000\n",
            "Name: DURATION, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK05xl_Phfc-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "f59f0aa7-cbb9-49a2-f406-ecbedbc83613"
      },
      "source": [
        "model.eval()\n",
        "loop = tqdm(dev_dataset, position=0, leave=True)\n",
        "df = pd.DataFrame(None, columns=[\"TEXT\", \"REAL TEXT\", \"BOOK TITLE\", \"DURATION\"])\n",
        "\n",
        "for batch_idx, (waveform, transcription, booktitle, duration) in enumerate(loop):\n",
        "    waveform = waveform[0].to(DEVICE).unsqueeze(0)\n",
        "    valid_lengths = torch.tensor([waveform.shape[-1]], device=DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        log_probs, encoded_len, greedy_predictions = model(input_signal=waveform, input_signal_length=valid_lengths)\n",
        "        transcriptions = beam_search_lm(log_probs=log_probs, log_probs_length=encoded_len)\n",
        "\n",
        "    best_transcriptions = get_best_transcriptions(transcriptions)\n",
        "    df = df.append({\"TEXT\": best_transcriptions[0], \"REAL TEXT\": transcription, \"BOOK TITLE\": booktitle, \"DURATION\": duration}, ignore_index=True)\n",
        "\n",
        "loop.close()\n",
        "df.to_csv(\"dev-clean.csv\")\n",
        "files.download(\"dev-clean.csv\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s][NeMo W 2021-08-16 12:00:04 patch_utils:50] torch.stft() signature has been updated for PyTorch 1.7+\n",
            "    Please update PyTorch to remain compatible with later versions of NeMo.\n",
            "[NeMo W 2021-08-16 12:00:04 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "    To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "      return torch.floor_divide(self, other)\n",
            "    \n",
            "100%|██████████| 63/63 [07:24<00:00,  7.05s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6979a727-037b-47d7-8406-c8d34dcdbdc9\", \"dev-clean.csv\", 584236)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQPJ9waaTPHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c63ee941-1bce-4f48-cfc8-f73f5612a444"
      },
      "source": [
        "model.eval()\n",
        "loop = tqdm(test_dataset, position=0, leave=True)\n",
        "df = pd.DataFrame(None, columns=[\"TEXT\", \"REAL TEXT\", \"BOOK TITLE\", \"DURATION\"])\n",
        "\n",
        "for batch_idx, (waveform, transcription, booktitle, duration) in enumerate(loop):\n",
        "    waveform = waveform[0].to(DEVICE).unsqueeze(0)\n",
        "    valid_lengths = torch.tensor([waveform.shape[-1]], device=DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        log_probs, encoded_len, greedy_predictions = model(input_signal=waveform, input_signal_length=valid_lengths)\n",
        "        transcriptions = beam_search_lm(log_probs=log_probs, log_probs_length=encoded_len)\n",
        "\n",
        "    best_transcriptions = get_best_transcriptions(transcriptions)\n",
        "    df = df.append({\"TEXT\": best_transcriptions[0], \"REAL TEXT\": transcription, \"BOOK TITLE\": booktitle, \"DURATION\": duration}, ignore_index=True)\n",
        "\n",
        "loop.close()\n",
        "df.to_csv(\"test-clean.csv\")\n",
        "files.download(\"test-clean.csv\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54/54 [07:41<00:00,  8.55s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_acab5475-fb1e-41a9-a033-e6788eb979a7\", \"test-clean.csv\", 569593)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H64SHq54hq5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492dbfbb-d748-4613-af41-363d61532411"
      },
      "source": [
        "model.eval()\n",
        "loop = tqdm(train_dataset, position=0, leave=True)\n",
        "df = pd.DataFrame(None, columns=[\"TEXT\", \"REAL TEXT\", \"BOOK TITLE\", \"DURATION\"])\n",
        "\n",
        "for batch_idx, (waveform, transcription, booktitle, duration) in enumerate(loop):\n",
        "    waveform = waveform[0].to(DEVICE).unsqueeze(0)\n",
        "    valid_lengths = torch.tensor([waveform.shape[-1]], device=DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        log_probs, encoded_len, greedy_predictions = model(input_signal=waveform, input_signal_length=valid_lengths)\n",
        "        transcriptions = beam_search_lm(log_probs=log_probs, log_probs_length=encoded_len)\n",
        "\n",
        "    best_transcriptions = get_best_transcriptions(transcriptions)\n",
        "    df = df.append({\"TEXT\": best_transcriptions[0], \"REAL TEXT\": transcription, \"BOOK TITLE\": booktitle, \"DURATION\": duration}, ignore_index=True)\n",
        "\n",
        "loop.close()\n",
        "df.to_csv(\"train-clean-100.csv\")\n",
        "files.download(\"train-clean-100.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/305 [00:51<4:20:32, 51.42s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX3TCRdXo7jP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
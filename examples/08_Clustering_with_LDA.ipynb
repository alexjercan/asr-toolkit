{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "import os\r\n",
    "import re\r\n",
    "import joblib\r\n",
    "\r\n",
    "from nltk import pos_tag, word_tokenize\r\n",
    "from nltk.corpus import stopwords, names\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.decomposition import LatentDirichletAllocation\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import pyLDAvis\r\n",
    "import pyLDAvis.sklearn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# Input and output filepaths\r\n",
    "train_clean_100_path = os.path.join(\"data\", \"train-clean-100.csv\")\r\n",
    "dev_clean_path = os.path.join(\"data\", \"dev-clean.csv\")\r\n",
    "test_clean_path = os.path.join(\"data\", \"test-clean.csv\")\r\n",
    "\r\n",
    "model_outpath = os.path.join(\"models\", \"model.jl\")\r\n",
    "\r\n",
    "pyLDAvis_outpath = os.path.join(\"view\", \"data.html\")\r\n",
    "\r\n",
    "os.makedirs(\"models\", exist_ok=True)\r\n",
    "os.makedirs(\"view\", exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# Read the csv files\r\n",
    "train_df = pd.read_csv(train_clean_100_path, index_col=0)\r\n",
    "dev_df = pd.read_csv(dev_clean_path, index_col=0)\r\n",
    "test_df = pd.read_csv(test_clean_path, index_col=0)\r\n",
    "\r\n",
    "train_df =  pd.DataFrame({\"TEXT\": train_df[\"REAL TEXT\"], \"BOOK\": train_df[\"BOOK TITLE\"]})\r\n",
    "dev_df = pd.DataFrame({\"TEXT\": dev_df[\"TEXT\"], \"BOOK\": dev_df[\"BOOK TITLE\"]})\r\n",
    "test_df = pd.DataFrame({\"TEXT\": test_df[\"TEXT\"], \"BOOK\": test_df[\"BOOK TITLE\"]})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# helper functions to normalize the words in the books\r\n",
    "# Used to remove short words. how short is a short words\r\n",
    "_short = 2\r\n",
    "\r\n",
    "# Used to remove stopwords from the english language\r\n",
    "_more_stopwords = set([\r\n",
    "    # interjections\r\n",
    "    \"oh\", \"ah\",\r\n",
    "    # useless\r\n",
    "    \"yes\", \"no\",\r\n",
    "    # archaic terms: they, you, triplet, to do, you\r\n",
    "    \"thy\", \"thou\", \"thrin\", \"didst\", \"thee\",\r\n",
    "    # names\r\n",
    "    *map(str.lower, names.words())\r\n",
    "])\r\n",
    "_stopwords = set(stopwords.words('english')) | _more_stopwords\r\n",
    "\r\n",
    "# Used to lemmatize words that are either adj, nouns or verbs\r\n",
    "# depending on _pos_tags otherwise it does nothing.\r\n",
    "_lemmatizer = WordNetLemmatizer()\r\n",
    "_pos_tags = [\"a\", \"n\", \"v\"]\r\n",
    "\r\n",
    "# Used for min/max filering. CountVectorizer removes words \r\n",
    "# that have a frequency higher that max_df. It also removes \r\n",
    "# words that appear in less documents than min_df.\r\n",
    "_max_df = 0.40\r\n",
    "_min_df = 3\r\n",
    "\r\n",
    "# https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\r\n",
    "# Used to decontract words that contain \"'\".\r\n",
    "def decontract(phrase: str):\r\n",
    "    # specific\r\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\r\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\r\n",
    "\r\n",
    "    # general\r\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\r\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\r\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\r\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\r\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\r\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\r\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\r\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\r\n",
    "    return phrase\r\n",
    "\r\n",
    "def is_not_short(word):\r\n",
    "    return len(word) > _short\r\n",
    "\r\n",
    "def not_in_stopwords(word):\r\n",
    "    return word not in _stopwords\r\n",
    "\r\n",
    "def lemmatize(pair):\r\n",
    "    word, pos = pair\r\n",
    "    pos = pos[0].lower()\r\n",
    "    if pos not in _pos_tags:\r\n",
    "        return word\r\n",
    "    return _lemmatizer.lemmatize(word, pos=pos)\r\n",
    "\r\n",
    "def document_analyzer(book: str):\r\n",
    "    book = str.lower(book)\r\n",
    "    book = decontract(book)\r\n",
    "    words = word_tokenize(book)\r\n",
    "    words = list(filter(is_not_short, words))\r\n",
    "    words = list(filter(not_in_stopwords, words))\r\n",
    "    words = list(map(lemmatize, pos_tag(words)))\r\n",
    "    return words"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "vectorizer = CountVectorizer(analyzer=document_analyzer, min_df=_min_df, max_df=_max_df)\r\n",
    "X_train = vectorizer.fit_transform([*train_df[\"TEXT\"].to_list(), *dev_df[\"TEXT\"].to_list()])\r\n",
    "X_dev = vectorizer.transform(dev_df[\"TEXT\"].to_list())\r\n",
    "X_test = vectorizer.transform(test_df[\"TEXT\"].to_list())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "lda = LatentDirichletAllocation(n_components=20, max_iter=50, evaluate_every=1, learning_method='online', verbose=1, n_jobs=-1)\r\n",
    "lda.fit_transform(X_train)\r\n",
    "y_hat = lda.transform(X_test)\r\n",
    "\r\n",
    "print(lda.score(X_dev))\r\n",
    "print(lda.perplexity(X_dev))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration: 1 of max_iter: 50, perplexity: 15362.2168\n",
      "iteration: 2 of max_iter: 50, perplexity: 11732.2175\n",
      "iteration: 3 of max_iter: 50, perplexity: 9704.4800\n",
      "iteration: 4 of max_iter: 50, perplexity: 8341.4871\n",
      "iteration: 5 of max_iter: 50, perplexity: 7394.2804\n",
      "iteration: 6 of max_iter: 50, perplexity: 6725.9729\n",
      "iteration: 7 of max_iter: 50, perplexity: 6250.3747\n",
      "iteration: 8 of max_iter: 50, perplexity: 5909.1312\n",
      "iteration: 9 of max_iter: 50, perplexity: 5662.8157\n",
      "iteration: 10 of max_iter: 50, perplexity: 5483.4603\n",
      "iteration: 11 of max_iter: 50, perplexity: 5351.8854\n",
      "iteration: 12 of max_iter: 50, perplexity: 5254.5401\n",
      "iteration: 13 of max_iter: 50, perplexity: 5181.9779\n",
      "iteration: 14 of max_iter: 50, perplexity: 5126.8747\n",
      "iteration: 15 of max_iter: 50, perplexity: 5084.4808\n",
      "iteration: 16 of max_iter: 50, perplexity: 5051.5442\n",
      "iteration: 17 of max_iter: 50, perplexity: 5025.5892\n",
      "iteration: 18 of max_iter: 50, perplexity: 5004.8857\n",
      "iteration: 19 of max_iter: 50, perplexity: 4988.0113\n",
      "iteration: 20 of max_iter: 50, perplexity: 4973.9090\n",
      "iteration: 21 of max_iter: 50, perplexity: 4962.2046\n",
      "iteration: 22 of max_iter: 50, perplexity: 4952.4392\n",
      "iteration: 23 of max_iter: 50, perplexity: 4944.0291\n",
      "iteration: 24 of max_iter: 50, perplexity: 4936.6525\n",
      "iteration: 25 of max_iter: 50, perplexity: 4930.1232\n",
      "iteration: 26 of max_iter: 50, perplexity: 4924.2522\n",
      "iteration: 27 of max_iter: 50, perplexity: 4918.9152\n",
      "iteration: 28 of max_iter: 50, perplexity: 4914.1527\n",
      "iteration: 29 of max_iter: 50, perplexity: 4909.7580\n",
      "iteration: 30 of max_iter: 50, perplexity: 4905.9997\n",
      "iteration: 31 of max_iter: 50, perplexity: 4902.3816\n",
      "iteration: 32 of max_iter: 50, perplexity: 4899.0240\n",
      "iteration: 33 of max_iter: 50, perplexity: 4895.9126\n",
      "iteration: 34 of max_iter: 50, perplexity: 4892.9854\n",
      "iteration: 35 of max_iter: 50, perplexity: 4890.3899\n",
      "iteration: 36 of max_iter: 50, perplexity: 4887.7721\n",
      "iteration: 37 of max_iter: 50, perplexity: 4885.3313\n",
      "iteration: 38 of max_iter: 50, perplexity: 4883.2087\n",
      "iteration: 39 of max_iter: 50, perplexity: 4881.1201\n",
      "iteration: 40 of max_iter: 50, perplexity: 4879.1315\n",
      "iteration: 41 of max_iter: 50, perplexity: 4877.1791\n",
      "iteration: 42 of max_iter: 50, perplexity: 4875.3298\n",
      "iteration: 43 of max_iter: 50, perplexity: 4873.5644\n",
      "iteration: 44 of max_iter: 50, perplexity: 4871.9692\n",
      "iteration: 45 of max_iter: 50, perplexity: 4870.3774\n",
      "iteration: 46 of max_iter: 50, perplexity: 4868.8863\n",
      "iteration: 47 of max_iter: 50, perplexity: 4867.5310\n",
      "iteration: 48 of max_iter: 50, perplexity: 4866.1296\n",
      "iteration: 49 of max_iter: 50, perplexity: 4864.7152\n",
      "iteration: 50 of max_iter: 50, perplexity: 4863.4339\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-183175.70727333846\n",
      "277690.41709838336\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# Functions for printing keywords for each topic\r\n",
    "def print_topics(model, vectorizer, top_n=10):\r\n",
    "    words = vectorizer.get_feature_names()\r\n",
    "\r\n",
    "    for idx, topic in enumerate(model.components_):\r\n",
    "        print(\"Topic %d:\" % (idx), end='')\r\n",
    "        print([words[i] for i in topic.argsort()[:-top_n - 1:-1]]) \r\n",
    "\r\n",
    "# Print the topics found by the LDA model\r\n",
    "print(\"Topics found via LDA:\")\r\n",
    "print_topics(lda, vectorizer, 15) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topics found via LDA:\n",
      "Topic 0:['uncle', 'girl', 'miss', 'fish', 'pirate', 'ship', 'seven', 'english', 'mountain', 'money', 'husband', 'missus', 'family', 'wall', 'indian']\n",
      "Topic 1:['bread', 'serve', 'butter', 'add', 'flour', 'salt', 'boil', 'cook', 'egg', 'sugar', 'mode', 'dish', 'slice', 'keats', 'soup']\n",
      "Topic 2:['babylon', 'armour', 'combatant', 'champion', 'device', 'list', 'competitor', 'circus', 'dexterity', 'housing', 'lance', 'feint', 'remount', 'embellish', 'euphrates']\n",
      "Topic 3:['captain', 'pilot', 'game', 'dat', 'cord', 'brag', 'owl', 'mate', 'quarter', 'yellow', 'thompson', 'caravan', 'paddle', 'passenger', 'petticoat']\n",
      "Topic 4:['income', 'labor', 'land', 'wheat', 'increase', 'rent', 'agent', 'material', 'value', 'product', 'cause', 'owner', 'principle', 'wealth', 'system']\n",
      "Topic 5:['girl', 'madame', 'boy', 'table', 'step', 'street', 'kill', 'dear', 'doctor', 'wall', 'barricade', 'everything', 'death', 'boat', 'window']\n",
      "Topic 6:['fish', 'power', 'eighteen', 'press', 'paper', 'doctor', 'certain', 'uncle', 'fire', 'blue', 'god', 'earth', 'sir', 'silver', 'law']\n",
      "Topic 7:['dream', 'power', 'experience', 'subject', 'nature', 'moral', 'mental', 'influence', 'physical', 'later', 'result', 'spiritual', 'individual', 'suggestion', 'system']\n",
      "Topic 8:['measure', 'music', 'beat', 'piano', 'musical', 'accent', 'group', 'tone', 'string', 'instrument', 'key', 'note', 'compound', 'conception', 'rhythm']\n",
      "Topic 9:['captain', 'reply', 'sir', 'power', 'badger', 'black', 'general', 'miss', 'till', 'thus', 'charm', 'doctor', 'dear', 'trigger', 'queen']\n",
      "Topic 10:['uncle', 'sir', 'corporal', 'miss', 'reply', 'missus', 'trim', 'honour', 'dear', 'story', 'thus', 'ill', 'wife', 'please', 'family']\n",
      "Topic 11:['ship', 'war', 'eighteen', 'captain', 'sea', 'president', 'government', 'boat', 'force', 'thousand', 'general', 'vessel', 'deck', 'american', 'english']\n",
      "Topic 12:['miss', 'missus', 'sir', 'girl', 'lady', 'reply', 'god', 'write', 'money', 'power', 'letter', 'manner', 'dear', 'wife', 'nature']\n",
      "Topic 13:['jew', 'jerusalem', 'medicine', 'physician', 'messiah', 'physic', 'god', 'remedy', 'disciple', 'bottle', 'cure', 'ruler', 'disease', 'restorative', 'priest']\n",
      "Topic 14:['girl', 'smile', 'black', 'star', 'figure', 'blue', 'dark', 'toward', 'shout', 'chair', 'tramp', 'across', 'strange', 'glance', 'slowly']\n",
      "Topic 15:['uncle', 'corporal', 'knit', 'trim', 'honour', 'quoth', 'please', 'story', 'bohemia', 'hast', 'seven', 'cap', 'attack', 'seam', 'whilst']\n",
      "Topic 16:['tree', 'boy', 'horse', 'princess', 'fire', 'around', 'river', 'big', 'black', 'green', 'land', 'mountain', 'snow', 'dead', 'laugh']\n",
      "Topic 17:['cheese', 'wine', 'drink', 'vintage', 'port', 'market', 'fit', 'flavor', 'english', 'swiss', 'gin', 'accord', 'combination', 'sip', 'nibble']\n",
      "Topic 18:['girl', 'play', 'street', 'subject', 'tree', 'doctor', 'bread', 'smile', 'step', 'power', 'missus', 'fire', 'land', 'sleep', 'captain']\n",
      "Topic 19:['power', 'uncle', 'girl', 'general', 'miss', 'thus', 'sir', 'ship', 'god', 'money', 'paper', 'madame', 'certain', 'england', 'dear']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "topic_df = pd.DataFrame({\"BOOK\": test_df[\"BOOK\"], \"TOPIC\": y_hat.argmax(axis=1)}, copy=True)\r\n",
    "\r\n",
    "topic_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 BOOK  TOPIC\n",
       "0                               Shakespeare's Sonnets     12\n",
       "1                             Mother Carey's Chickens     12\n",
       "2                       The Return of Sherlock Holmes     12\n",
       "3                    Alice's Adventures in Wonderland     16\n",
       "4   Gentle Measures in the Management and Training...     12\n",
       "5                          Aunt Jane's Nieces at Work     12\n",
       "6                              The Weapons of Mystery     12\n",
       "7                                      The Sunny Side     12\n",
       "8                                      Les Miserables     12\n",
       "9   Off on a Comet! a Journey through Planetary Space     12\n",
       "10                  The Exemplary Novels of Cervantes     12\n",
       "11                           The Underground Railroad     12\n",
       "12            The Quest of the Silver Fleece: A Novel     12\n",
       "13         Commentary on the Epistle to the Galatians     12\n",
       "14                                            Timaeus     12\n",
       "15                             Andersen's Fairy Tales     16\n",
       "16                 Life of Charlotte Bronte  Volume 1     12\n",
       "17  The History of England in Three Volumes, Vol.I...     12\n",
       "18                             The Foolish Dictionary     12\n",
       "19  Lectures on Landscape Delivered at Oxford in L...     12\n",
       "20                        Sonnets from the Portuguese     12\n",
       "21                              The Turn of the Screw     12\n",
       "22                                     A Simple Story     12\n",
       "23                                 The Descent of Man     12\n",
       "24                                        O Pioneers!     16\n",
       "25                                       Viking Tales     16\n",
       "26              Twenty Thousand Leagues Under the Sea     12\n",
       "27                               The Analysis of Mind     12\n",
       "28           The Book of Stories for the Story-teller     16\n",
       "29                                    Ten Years Later     12\n",
       "30                                   The Fixed Period     12\n",
       "31              Five Little Peppers and How They Grew     16\n",
       "32                                         Robin Hood     12\n",
       "33  The Complete Memoirs of Jacques Casanova de Se...     12\n",
       "34                               The Boarded-Up House     12\n",
       "35                     The Gilded Age A tale of today     12\n",
       "36                                 The Scarlet Letter     12\n",
       "37                                Eight Harvard Poets     16\n",
       "38           A Journey into the Interior of the Earth     12\n",
       "39                                      Hoof and Claw     16\n",
       "40  Sky Island Being the Further Exciting Adventur...     16\n",
       "41            A Portrait of the Artist as a Young Man     12\n",
       "42                                          Adam Bede     12\n",
       "43  The Story of \"Mormonism\" and The Philosophy of...     12\n",
       "44                             Poems of William Blake     16\n",
       "45              Abraham Lincoln: a History  Volume 01     12\n",
       "46  History of the Decline and Fall of the Roman E...     12\n",
       "47                                     The Dead Alive     12\n",
       "48                    Edison, His Life and Inventions     12\n",
       "49                        Theory of the Leisure Class     12\n",
       "50                                 Alexander's Bridge     12\n",
       "51                           The Last of the Mohicans     12\n",
       "52                           The Patchwork Girl of Oz     16\n",
       "53                                      Wylder's Hand     12"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOOK</th>\n",
       "      <th>TOPIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mother Carey's Chickens</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Return of Sherlock Holmes</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice's Adventures in Wonderland</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gentle Measures in the Management and Training...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aunt Jane's Nieces at Work</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Weapons of Mystery</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Sunny Side</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Les Miserables</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Off on a Comet! a Journey through Planetary Space</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Exemplary Novels of Cervantes</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Underground Railroad</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Quest of the Silver Fleece: A Novel</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Commentary on the Epistle to the Galatians</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timaeus</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Andersen's Fairy Tales</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Life of Charlotte Bronte  Volume 1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The History of England in Three Volumes, Vol.I...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Foolish Dictionary</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lectures on Landscape Delivered at Oxford in L...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sonnets from the Portuguese</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Turn of the Screw</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A Simple Story</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Descent of Man</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>O Pioneers!</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Viking Tales</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Twenty Thousand Leagues Under the Sea</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The Analysis of Mind</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The Book of Stories for the Story-teller</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ten Years Later</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The Fixed Period</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Five Little Peppers and How They Grew</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Robin Hood</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The Complete Memoirs of Jacques Casanova de Se...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The Boarded-Up House</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Gilded Age A tale of today</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The Scarlet Letter</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Eight Harvard Poets</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A Journey into the Interior of the Earth</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hoof and Claw</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Sky Island Being the Further Exciting Adventur...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A Portrait of the Artist as a Young Man</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Adam Bede</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The Story of \"Mormonism\" and The Philosophy of...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Poems of William Blake</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Abraham Lincoln: a History  Volume 01</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>History of the Decline and Fall of the Roman E...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>The Dead Alive</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Edison, His Life and Inventions</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Theory of the Leisure Class</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Alexander's Bridge</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>The Last of the Mohicans</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>The Patchwork Girl of Oz</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Wylder's Hand</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "model = {\"vectorizer\": vectorizer, \"lda\": lda}\r\n",
    "joblib.dump(model, model_outpath)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['models\\\\model.jl']"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "pyLDAvis.enable_notebook()\r\n",
    "data = pyLDAvis.sklearn.prepare(lda, X_train, vectorizer, mds='tsne')\r\n",
    "pyLDAvis.save_html(data, pyLDAvis_outpath)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jercan.a.constantin\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:691: FutureWarning: 'square_distances' has been introduced in 0.24 to help phase out legacy squaring behavior. The 'legacy' setting will be removed in 1.1 (renaming of 0.26), and the default setting will be changed to True. In 1.3, 'square_distances' will be removed altogether, and distances will be squared by default. Set 'square_distances'=True to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b1bf7ce53402eb598e8215c6005ec7d9cda2e0311a36b09829578fce466cd3cd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}